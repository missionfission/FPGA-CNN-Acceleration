name: "Inception_v3"
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 299
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/mnt/disk/ILSVRC2012/300px_ilsvrc12_train_lmdb"
    batch_size: 20
    backend: LMDB
  }
}
layer {
  name: "conv_conv2d"
  type: "Convolution"
  bottom: "data"
  top: "conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 32
    pad: 0
    kernel_size: 3
    stride: 2
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "conv_conv2d"
  top: "conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv_conv2d_relu"
  type: "ReLU"
  bottom: "conv_conv2d_bn"
  top: "conv_conv2d_relu"
}
layer {
  name: "conv_1_1/conv2d"
  type: "Convolution"
  bottom: "conv_conv2d_relu"
  top: "conv_1_1/conv2d"
  convolution_param {
    bias_term: false
    num_output: 32
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "conv_1_1/conv2d_bn"
  type: "BatchNorm"
  bottom: "conv_1_1/conv2d"
  top: "conv_1_1/conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv_1_1/conv2d_relu"
  type: "ReLU"
  bottom: "conv_1_1/conv2d_bn"
  top: "conv_1_1/conv2d_relu"
}
layer {
  name: "conv_2_2/conv2d"
  type: "Convolution"
  bottom: "conv_1_1/conv2d_relu"
  top: "conv_2_2/conv2d"
  convolution_param {
    bias_term: false
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "conv_2_2/conv2d_bn"
  type: "BatchNorm"
  bottom: "conv_2_2/conv2d"
  top: "conv_2_2/conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv_2_2/conv2d_relu"
  type: "ReLU"
  bottom: "conv_2_2/conv2d_bn"
  top: "conv_2_2/conv2d_relu"
}
layer {
  name: "pool"
  type: "Pooling"
  bottom: "conv_2_2/conv2d_relu"
  top: "pool"
  pooling_param {
    pool: MAX
    pad: 0
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv_3_3/conv2d"
  type: "Convolution"
  bottom: "pool"
  top: "conv_3_3/conv2d"
  convolution_param {
    bias_term: false
    num_output: 80
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "conv_3_3/conv2d_bn"
  type: "BatchNorm"
  bottom: "conv_3_3/conv2d"
  top: "conv_3_3/conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv_3_3/conv2d_relu"
  type: "ReLU"
  bottom: "conv_3_3/conv2d_bn"
  top: "conv_3_3/conv2d_relu"
}
layer {
  name: "conv_4_4/conv2d"
  type: "Convolution"
  bottom: "conv_3_3/conv2d_relu"
  top: "conv_4_4/conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "conv_4_4/conv2d_bn"
  type: "BatchNorm"
  bottom: "conv_4_4/conv2d"
  top: "conv_4_4/conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv_4_4/conv2d_relu"
  type: "ReLU"
  bottom: "conv_4_4/conv2d_bn"
  top: "conv_4_4/conv2d_relu"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv_4_4/conv2d_relu"
  top: "pool1"
  pooling_param {
    pool: MAX
    pad: 0
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "mixed_conv/conv2d"
  type: "Convolution"
  bottom: "pool1"
  top: "mixed_conv/conv2d"
  convolution_param {
    bias_term: false
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_conv/conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_conv/conv2d"
  top: "mixed_conv/conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_conv/conv2d_relu"
  type: "ReLU"
  bottom: "mixed_conv/conv2d_bn"
  top: "mixed_conv/conv2d_relu"
}
layer {
  name: "mixed_tower/conv_conv2d"
  type: "Convolution"
  bottom: "pool1"
  top: "mixed_tower/conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 48
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_tower/conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_tower/conv_conv2d"
  top: "mixed_tower/conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_tower/conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_tower/conv_conv2d_bn"
  top: "mixed_tower/conv_conv2d_relu"
}
layer {
  name: "mixed_tower/conv_1_conv2d"
  type: "Convolution"
  bottom: "mixed_tower/conv_conv2d_relu"
  top: "mixed_tower/conv_1_conv2d"
  convolution_param {
    bias_term: false
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_tower/conv_1_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_tower/conv_1_conv2d"
  top: "mixed_tower/conv_1_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_tower/conv_1_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_tower/conv_1_conv2d_bn"
  top: "mixed_tower/conv_1_conv2d_relu"
}
layer {
  name: "mixed_tower/1_conv_conv2d"
  type: "Convolution"
  bottom: "pool1"
  top: "mixed_tower/1_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_tower/1_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_tower/1_conv_conv2d"
  top: "mixed_tower/1_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_tower/1_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_tower/1_conv_conv2d_bn"
  top: "mixed_tower/1_conv_conv2d_relu"
}
layer {
  name: "mixed_tower/1_conv_1_conv2d"
  type: "Convolution"
  bottom: "mixed_tower/1_conv_conv2d_relu"
  top: "mixed_tower/1_conv_1_conv2d"
  convolution_param {
    bias_term: false
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_tower/1_conv_1_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_tower/1_conv_1_conv2d"
  top: "mixed_tower/1_conv_1_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_tower/1_conv_1_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_tower/1_conv_1_conv2d_bn"
  top: "mixed_tower/1_conv_1_conv2d_relu"
}
layer {
  name: "mixed_tower/1_conv_2_conv2d"
  type: "Convolution"
  bottom: "mixed_tower/1_conv_1_conv2d_relu"
  top: "mixed_tower/1_conv_2_conv2d"
  convolution_param {
    bias_term: false
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_tower/1_conv_2_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_tower/1_conv_2_conv2d"
  top: "mixed_tower/1_conv_2_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_tower/1_conv_2_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_tower/1_conv_2_conv2d_bn"
  top: "mixed_tower/1_conv_2_conv2d_relu"
}
layer {
  name: "mixed_tower/AVG_pool"
  type: "Pooling"
  bottom: "pool1"
  top: "mixed_tower/AVG_pool"
  pooling_param {
    pool: AVE
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "mixed_tower/2_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_tower/AVG_pool"
  top: "mixed_tower/2_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_tower/2_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_tower/2_conv_conv2d"
  top: "mixed_tower/2_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_tower/2_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_tower/2_conv_conv2d_bn"
  top: "mixed_tower/2_conv_conv2d_relu"
}
layer {
  name: "mixed_tower/chconcat"
  bottom: "mixed_conv/conv2d_relu"
  bottom: "mixed_tower/conv_1_conv2d_relu"
  bottom: "mixed_tower/1_conv_2_conv2d_relu"
  bottom: "mixed_tower/2_conv_conv2d_relu"
  top: "mixed_tower/chconcat"
  type: "Concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mixed_1/conv_conv2d"
  type: "Convolution"
  bottom: "mixed_tower/chconcat"
  top: "mixed_1/conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_1/conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_1/conv_conv2d"
  top: "mixed_1/conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_1/conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_1/conv_conv2d_bn"
  top: "mixed_1/conv_conv2d_relu"
}
layer {
  name: "mixed_1/tower_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_tower/chconcat"
  top: "mixed_1/tower_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 48
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_1/tower_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_1/tower_conv_conv2d"
  top: "mixed_1/tower_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_1/tower_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_1/tower_conv_conv2d_bn"
  top: "mixed_1/tower_conv_conv2d_relu"
}
layer {
  name: "mixed_1/tower_conv_1_conv2d"
  type: "Convolution"
  bottom: "mixed_1/tower_conv_conv2d_relu"
  top: "mixed_1/tower_conv_1_conv2d"
  convolution_param {
    bias_term: false
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_1/tower_conv_1_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_1/tower_conv_1_conv2d"
  top: "mixed_1/tower_conv_1_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_1/tower_conv_1_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_1/tower_conv_1_conv2d_bn"
  top: "mixed_1/tower_conv_1_conv2d_relu"
}
layer {
  name: "mixed_1/tower_1_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_tower/chconcat"
  top: "mixed_1/tower_1_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_1/tower_1_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_1/tower_1_conv_conv2d"
  top: "mixed_1/tower_1_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_1/tower_1_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_1/tower_1_conv_conv2d_bn"
  top: "mixed_1/tower_1_conv_conv2d_relu"
}
layer {
  name: "mixed_1/tower_1_conv_1_conv2d"
  type: "Convolution"
  bottom: "mixed_1/tower_1_conv_conv2d_relu"
  top: "mixed_1/tower_1_conv_1_conv2d"
  convolution_param {
    bias_term: false
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_1/tower_1_conv_1_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_1/tower_1_conv_1_conv2d"
  top: "mixed_1/tower_1_conv_1_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_1/tower_1_conv_1_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_1/tower_1_conv_1_conv2d_bn"
  top: "mixed_1/tower_1_conv_1_conv2d_relu"
}
layer {
  name: "mixed_1/tower_1_conv_2_conv2d"
  type: "Convolution"
  bottom: "mixed_1/tower_1_conv_1_conv2d_relu"
  top: "mixed_1/tower_1_conv_2_conv2d"
  convolution_param {
    bias_term: false
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_1/tower_1_conv_2_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_1/tower_1_conv_2_conv2d"
  top: "mixed_1/tower_1_conv_2_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_1/tower_1_conv_2_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_1/tower_1_conv_2_conv2d_bn"
  top: "mixed_1/tower_1_conv_2_conv2d_relu"
}
layer {
  name: "mixed_1/tower_2_AVG_pool"
  type: "Pooling"
  bottom: "mixed_tower/chconcat"
  top: "mixed_1/tower_2_AVG_pool"
  pooling_param {
    pool: AVE
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "mixed_1/tower_2_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_1/tower_2_AVG_pool"
  top: "mixed_1/tower_2_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_1/tower_2_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_1/tower_2_conv_conv2d"
  top: "mixed_1/tower_2_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_1/tower_2_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_1/tower_2_conv_conv2d_bn"
  top: "mixed_1/tower_2_conv_conv2d_relu"
}
layer {
  name: "mixed_1/chconcat"
  bottom: "mixed_1/conv_conv2d_relu"
bottom: "mixed_1/tower_conv_1_conv2d_relu"
bottom: "mixed_1/tower_1_conv_2_conv2d_relu"
bottom: "mixed_1/tower_2_conv_conv2d_relu"

  top: "mixed_1/chconcat"
  type: "Concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mixed_2/conv_conv2d"
  type: "Convolution"
  bottom: "mixed_1/chconcat"
  top: "mixed_2/conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_2/conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_2/conv_conv2d"
  top: "mixed_2/conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_2/conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_2/conv_conv2d_bn"
  top: "mixed_2/conv_conv2d_relu"
}
layer {
  name: "mixed_2/tower_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_1/chconcat"
  top: "mixed_2/tower_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 48
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_2/tower_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_2/tower_conv_conv2d"
  top: "mixed_2/tower_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_2/tower_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_2/tower_conv_conv2d_bn"
  top: "mixed_2/tower_conv_conv2d_relu"
}
layer {
  name: "mixed_2/tower_conv_1_conv2d"
  type: "Convolution"
  bottom: "mixed_2/tower_conv_conv2d_relu"
  top: "mixed_2/tower_conv_1_conv2d"
  convolution_param {
    bias_term: false
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_2/tower_conv_1_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_2/tower_conv_1_conv2d"
  top: "mixed_2/tower_conv_1_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_2/tower_conv_1_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_2/tower_conv_1_conv2d_bn"
  top: "mixed_2/tower_conv_1_conv2d_relu"
}
layer {
  name: "mixed_2/tower_1_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_1/chconcat"
  top: "mixed_2/tower_1_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_2/tower_1_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_2/tower_1_conv_conv2d"
  top: "mixed_2/tower_1_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_2/tower_1_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_2/tower_1_conv_conv2d_bn"
  top: "mixed_2/tower_1_conv_conv2d_relu"
}
layer {
  name: "mixed_2/tower_1_conv_1_conv2d"
  type: "Convolution"
  bottom: "mixed_2/tower_1_conv_conv2d_relu"
  top: "mixed_2/tower_1_conv_1_conv2d"
  convolution_param {
    bias_term: false
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_2/tower_1_conv_1_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_2/tower_1_conv_1_conv2d"
  top: "mixed_2/tower_1_conv_1_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_2/tower_1_conv_1_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_2/tower_1_conv_1_conv2d_bn"
  top: "mixed_2/tower_1_conv_1_conv2d_relu"
}
layer {
  name: "mixed_2/tower_1_conv_2_conv2d"
  type: "Convolution"
  bottom: "mixed_2/tower_1_conv_1_conv2d_relu"
  top: "mixed_2/tower_1_conv_2_conv2d"
  convolution_param {
    bias_term: false
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_2/tower_1_conv_2_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_2/tower_1_conv_2_conv2d"
  top: "mixed_2/tower_1_conv_2_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_2/tower_1_conv_2_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_2/tower_1_conv_2_conv2d_bn"
  top: "mixed_2/tower_1_conv_2_conv2d_relu"
}
layer {
  name: "mixed_2/tower_2_AVG_pool"
  type: "Pooling"
  bottom: "mixed_1/chconcat"
  top: "mixed_2/tower_2_AVG_pool"
  pooling_param {
    pool: AVE
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "mixed_2/tower_2_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_2/tower_2_AVG_pool"
  top: "mixed_2/tower_2_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_2/tower_2_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_2/tower_2_conv_conv2d"
  top: "mixed_2/tower_2_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_2/tower_2_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_2/tower_2_conv_conv2d_bn"
  top: "mixed_2/tower_2_conv_conv2d_relu"
}
layer {
  name: "mixed_2/chconcat"
  bottom: "mixed_2/conv_conv2d_relu"
bottom: "mixed_2/tower_conv_1_conv2d_relu"
bottom: "mixed_2/tower_1_conv_2_conv2d_relu"
bottom: "mixed_2/tower_2_conv_conv2d_relu"

  top: "mixed_2/chconcat"
  type: "Concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mixed_3/conv_conv2d"
  type: "Convolution"
  bottom: "mixed_2/chconcat"
  top: "mixed_3/conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 384
    pad: 0
    kernel_size: 3
    stride: 2
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_3/conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_3/conv_conv2d"
  top: "mixed_3/conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_3/conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_3/conv_conv2d_bn"
  top: "mixed_3/conv_conv2d_relu"
}
layer {
  name: "mixed_3/tower_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_2/chconcat"
  top: "mixed_3/tower_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_3/tower_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_3/tower_conv_conv2d"
  top: "mixed_3/tower_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_3/tower_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_3/tower_conv_conv2d_bn"
  top: "mixed_3/tower_conv_conv2d_relu"
}
layer {
  name: "mixed_3/tower_conv_1_conv2d"
  type: "Convolution"
  bottom: "mixed_3/tower_conv_conv2d_relu"
  top: "mixed_3/tower_conv_1_conv2d"
  convolution_param {
    bias_term: false
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_3/tower_conv_1_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_3/tower_conv_1_conv2d"
  top: "mixed_3/tower_conv_1_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_3/tower_conv_1_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_3/tower_conv_1_conv2d_bn"
  top: "mixed_3/tower_conv_1_conv2d_relu"
}
layer {
  name: "mixed_3/tower_conv_2_conv2d"
  type: "Convolution"
  bottom: "mixed_3/tower_conv_1_conv2d_relu"
  top: "mixed_3/tower_conv_2_conv2d"
  convolution_param {
    bias_term: false
    num_output: 96
    pad: 0
    kernel_size: 3
    stride: 2
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_3/tower_conv_2_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_3/tower_conv_2_conv2d"
  top: "mixed_3/tower_conv_2_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_3/tower_conv_2_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_3/tower_conv_2_conv2d_bn"
  top: "mixed_3/tower_conv_2_conv2d_relu"
}
layer {
  name: "mixed_3/max_pool"
  type: "Pooling"
  bottom: "mixed_2/chconcat"
  top: "mixed_3/max_pool"
  pooling_param {
    pool: MAX
    pad: 0
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "mixed_3/chconcat"
  bottom: "mixed_3/max_pool"
bottom: "mixed_3/conv_conv2d_relu"
bottom: "mixed_3/tower_conv_2_conv2d_relu"

  top: "mixed_3/chconcat"
  type: "Concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mixed_4/conv_conv2d"
  type: "Convolution"
  bottom: "mixed_3/chconcat"
  top: "mixed_4/conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_4/conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_4/conv_conv2d"
  top: "mixed_4/conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_4/conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_4/conv_conv2d_bn"
  top: "mixed_4/conv_conv2d_relu"
}
layer {
  name: "mixed_4/tower_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_3/chconcat"
  top: "mixed_4/tower_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_4/tower_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_4/tower_conv_conv2d"
  top: "mixed_4/tower_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_4/tower_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_4/tower_conv_conv2d_bn"
  top: "mixed_4/tower_conv_conv2d_relu"
}
layer {
  name: "mixed_4/tower_conv_1_conv2d"
  type: "Convolution"
  bottom: "mixed_4/tower_conv_conv2d_relu"
  top: "mixed_4/tower_conv_1_conv2d"
  convolution_param {
    bias_term: false
    num_output: 128
    pad_h: 0
pad_w: 3
    kernel_h: 1
kernel_w: 7
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_4/tower_conv_1_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_4/tower_conv_1_conv2d"
  top: "mixed_4/tower_conv_1_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_4/tower_conv_1_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_4/tower_conv_1_conv2d_bn"
  top: "mixed_4/tower_conv_1_conv2d_relu"
}
layer {
  name: "mixed_4/tower_conv_2_conv2d"
  type: "Convolution"
  bottom: "mixed_4/tower_conv_1_conv2d_relu"
  top: "mixed_4/tower_conv_2_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad_h: 3
pad_w: 0
    kernel_h: 7
kernel_w: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_4/tower_conv_2_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_4/tower_conv_2_conv2d"
  top: "mixed_4/tower_conv_2_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_4/tower_conv_2_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_4/tower_conv_2_conv2d_bn"
  top: "mixed_4/tower_conv_2_conv2d_relu"
}
layer {
  name: "mixed_4/tower_1_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_3/chconcat"
  top: "mixed_4/tower_1_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_4/tower_1_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_4/tower_1_conv_conv2d"
  top: "mixed_4/tower_1_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_4/tower_1_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_4/tower_1_conv_conv2d_bn"
  top: "mixed_4/tower_1_conv_conv2d_relu"
}
layer {
  name: "mixed_4/tower_1_conv_1_conv2d"
  type: "Convolution"
  bottom: "mixed_4/tower_1_conv_conv2d_relu"
  top: "mixed_4/tower_1_conv_1_conv2d"
  convolution_param {
    bias_term: false
    num_output: 128
    pad_h: 3
pad_w: 0
    kernel_h: 7
kernel_w: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_4/tower_1_conv_1_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_4/tower_1_conv_1_conv2d"
  top: "mixed_4/tower_1_conv_1_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_4/tower_1_conv_1_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_4/tower_1_conv_1_conv2d_bn"
  top: "mixed_4/tower_1_conv_1_conv2d_relu"
}
layer {
  name: "mixed_4/tower_1_conv_2_conv2d"
  type: "Convolution"
  bottom: "mixed_4/tower_1_conv_1_conv2d_relu"
  top: "mixed_4/tower_1_conv_2_conv2d"
  convolution_param {
    bias_term: false
    num_output: 128
    pad_h: 0
pad_w: 3
    kernel_h: 1
kernel_w: 7
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_4/tower_1_conv_2_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_4/tower_1_conv_2_conv2d"
  top: "mixed_4/tower_1_conv_2_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_4/tower_1_conv_2_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_4/tower_1_conv_2_conv2d_bn"
  top: "mixed_4/tower_1_conv_2_conv2d_relu"
}
layer {
  name: "mixed_4/tower_1_conv_3_conv2d"
  type: "Convolution"
  bottom: "mixed_4/tower_1_conv_2_conv2d_relu"
  top: "mixed_4/tower_1_conv_3_conv2d"
  convolution_param {
    bias_term: false
    num_output: 128
    pad_h: 3
pad_w: 0
    kernel_h: 7
kernel_w: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_4/tower_1_conv_3_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_4/tower_1_conv_3_conv2d"
  top: "mixed_4/tower_1_conv_3_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_4/tower_1_conv_3_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_4/tower_1_conv_3_conv2d_bn"
  top: "mixed_4/tower_1_conv_3_conv2d_relu"
}
layer {
  name: "mixed_4/tower_1_conv_4_conv2d"
  type: "Convolution"
  bottom: "mixed_4/tower_1_conv_3_conv2d_relu"
  top: "mixed_4/tower_1_conv_4_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad_h: 0
pad_w: 3
    kernel_h: 1
kernel_w: 7
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_4/tower_1_conv_4_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_4/tower_1_conv_4_conv2d"
  top: "mixed_4/tower_1_conv_4_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_4/tower_1_conv_4_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_4/tower_1_conv_4_conv2d_bn"
  top: "mixed_4/tower_1_conv_4_conv2d_relu"
}
layer {
  name: "mixed_4/tower_2_AVG_pool"
  type: "Pooling"
  bottom: "mixed_3/chconcat"
  top: "mixed_4/tower_2_AVG_pool"
  pooling_param {
    pool: AVE
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "mixed_4/tower_2_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_4/tower_2_AVG_pool"
  top: "mixed_4/tower_2_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_4/tower_2_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_4/tower_2_conv_conv2d"
  top: "mixed_4/tower_2_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_4/tower_2_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_4/tower_2_conv_conv2d_bn"
  top: "mixed_4/tower_2_conv_conv2d_relu"
}
layer {
  name: "mixed_4/chconcat"
  bottom: "mixed_4/conv_conv2d_relu"
bottom: "mixed_4/tower_conv_2_conv2d_relu"
bottom: "mixed_4/tower_1_conv_4_conv2d_relu"
bottom: "mixed_4/tower_2_conv_conv2d_relu"

  top: "mixed_4/chconcat"
  type: "Concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mixed_5/conv_conv2d"
  type: "Convolution"
  bottom: "mixed_4/chconcat"
  top: "mixed_5/conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_5/conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_5/conv_conv2d"
  top: "mixed_5/conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_5/conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_5/conv_conv2d_bn"
  top: "mixed_5/conv_conv2d_relu"
}
layer {
  name: "mixed_5/tower_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_4/chconcat"
  top: "mixed_5/tower_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 160
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_5/tower_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_5/tower_conv_conv2d"
  top: "mixed_5/tower_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_5/tower_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_5/tower_conv_conv2d_bn"
  top: "mixed_5/tower_conv_conv2d_relu"
}
layer {
  name: "mixed_5/tower_conv_1_conv2d"
  type: "Convolution"
  bottom: "mixed_5/tower_conv_conv2d_relu"
  top: "mixed_5/tower_conv_1_conv2d"
  convolution_param {
    bias_term: false
    num_output: 160
    pad_h: 0
pad_w: 3
    kernel_h: 1
kernel_w: 7
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_5/tower_conv_1_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_5/tower_conv_1_conv2d"
  top: "mixed_5/tower_conv_1_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_5/tower_conv_1_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_5/tower_conv_1_conv2d_bn"
  top: "mixed_5/tower_conv_1_conv2d_relu"
}
layer {
  name: "mixed_5/tower_conv_2_conv2d"
  type: "Convolution"
  bottom: "mixed_5/tower_conv_1_conv2d_relu"
  top: "mixed_5/tower_conv_2_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad_h: 3
pad_w: 0
    kernel_h: 7
kernel_w: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_5/tower_conv_2_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_5/tower_conv_2_conv2d"
  top: "mixed_5/tower_conv_2_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_5/tower_conv_2_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_5/tower_conv_2_conv2d_bn"
  top: "mixed_5/tower_conv_2_conv2d_relu"
}
layer {
  name: "mixed_5/tower_1_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_4/chconcat"
  top: "mixed_5/tower_1_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 160
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_5/tower_1_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_5/tower_1_conv_conv2d"
  top: "mixed_5/tower_1_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_5/tower_1_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_5/tower_1_conv_conv2d_bn"
  top: "mixed_5/tower_1_conv_conv2d_relu"
}
layer {
  name: "mixed_5/tower_1_conv_1_conv2d"
  type: "Convolution"
  bottom: "mixed_5/tower_1_conv_conv2d_relu"
  top: "mixed_5/tower_1_conv_1_conv2d"
  convolution_param {
    bias_term: false
    num_output: 160
    pad_h: 3
pad_w: 0
    kernel_h: 7
kernel_w: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_5/tower_1_conv_1_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_5/tower_1_conv_1_conv2d"
  top: "mixed_5/tower_1_conv_1_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_5/tower_1_conv_1_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_5/tower_1_conv_1_conv2d_bn"
  top: "mixed_5/tower_1_conv_1_conv2d_relu"
}
layer {
  name: "mixed_5/tower_1_conv_2_conv2d"
  type: "Convolution"
  bottom: "mixed_5/tower_1_conv_1_conv2d_relu"
  top: "mixed_5/tower_1_conv_2_conv2d"
  convolution_param {
    bias_term: false
    num_output: 160
    pad_h: 0
pad_w: 3
    kernel_h: 1
kernel_w: 7
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_5/tower_1_conv_2_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_5/tower_1_conv_2_conv2d"
  top: "mixed_5/tower_1_conv_2_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_5/tower_1_conv_2_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_5/tower_1_conv_2_conv2d_bn"
  top: "mixed_5/tower_1_conv_2_conv2d_relu"
}
layer {
  name: "mixed_5/tower_1_conv_3_conv2d"
  type: "Convolution"
  bottom: "mixed_5/tower_1_conv_2_conv2d_relu"
  top: "mixed_5/tower_1_conv_3_conv2d"
  convolution_param {
    bias_term: false
    num_output: 160
    pad_h: 3
pad_w: 0
    kernel_h: 7
kernel_w: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_5/tower_1_conv_3_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_5/tower_1_conv_3_conv2d"
  top: "mixed_5/tower_1_conv_3_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_5/tower_1_conv_3_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_5/tower_1_conv_3_conv2d_bn"
  top: "mixed_5/tower_1_conv_3_conv2d_relu"
}
layer {
  name: "mixed_5/tower_1_conv_4_conv2d"
  type: "Convolution"
  bottom: "mixed_5/tower_1_conv_3_conv2d_relu"
  top: "mixed_5/tower_1_conv_4_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad_h: 0
pad_w: 3
    kernel_h: 1
kernel_w: 7
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_5/tower_1_conv_4_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_5/tower_1_conv_4_conv2d"
  top: "mixed_5/tower_1_conv_4_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_5/tower_1_conv_4_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_5/tower_1_conv_4_conv2d_bn"
  top: "mixed_5/tower_1_conv_4_conv2d_relu"
}
layer {
  name: "mixed_5/tower_2_AVG_pool"
  type: "Pooling"
  bottom: "mixed_4/chconcat"
  top: "mixed_5/tower_2_AVG_pool"
  pooling_param {
    pool: AVE
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "mixed_5/tower_2_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_5/tower_2_AVG_pool"
  top: "mixed_5/tower_2_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_5/tower_2_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_5/tower_2_conv_conv2d"
  top: "mixed_5/tower_2_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_5/tower_2_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_5/tower_2_conv_conv2d_bn"
  top: "mixed_5/tower_2_conv_conv2d_relu"
}
layer {
  name: "mixed_5/chconcat"
  bottom: "mixed_5/conv_conv2d_relu"
bottom: "mixed_5/tower_conv_2_conv2d_relu"
bottom: "mixed_5/tower_1_conv_4_conv2d_relu"
bottom: "mixed_5/tower_2_conv_conv2d_relu"

  top: "mixed_5/chconcat"
  type: "Concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mixed_6/conv_conv2d"
  type: "Convolution"
  bottom: "mixed_5/chconcat"
  top: "mixed_6/conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_6/conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_6/conv_conv2d"
  top: "mixed_6/conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_6/conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_6/conv_conv2d_bn"
  top: "mixed_6/conv_conv2d_relu"
}
layer {
  name: "mixed_6/tower_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_5/chconcat"
  top: "mixed_6/tower_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 160
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_6/tower_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_6/tower_conv_conv2d"
  top: "mixed_6/tower_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_6/tower_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_6/tower_conv_conv2d_bn"
  top: "mixed_6/tower_conv_conv2d_relu"
}
layer {
  name: "mixed_6/tower_conv_1_conv2d"
  type: "Convolution"
  bottom: "mixed_6/tower_conv_conv2d_relu"
  top: "mixed_6/tower_conv_1_conv2d"
  convolution_param {
    bias_term: false
    num_output: 160
    pad_h: 0
pad_w: 3
    kernel_h: 1
kernel_w: 7
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_6/tower_conv_1_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_6/tower_conv_1_conv2d"
  top: "mixed_6/tower_conv_1_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_6/tower_conv_1_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_6/tower_conv_1_conv2d_bn"
  top: "mixed_6/tower_conv_1_conv2d_relu"
}
layer {
  name: "mixed_6/tower_conv_2_conv2d"
  type: "Convolution"
  bottom: "mixed_6/tower_conv_1_conv2d_relu"
  top: "mixed_6/tower_conv_2_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad_h: 3
pad_w: 0
    kernel_h: 7
kernel_w: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_6/tower_conv_2_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_6/tower_conv_2_conv2d"
  top: "mixed_6/tower_conv_2_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_6/tower_conv_2_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_6/tower_conv_2_conv2d_bn"
  top: "mixed_6/tower_conv_2_conv2d_relu"
}
layer {
  name: "mixed_6/tower_1_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_5/chconcat"
  top: "mixed_6/tower_1_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 160
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_6/tower_1_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_6/tower_1_conv_conv2d"
  top: "mixed_6/tower_1_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_6/tower_1_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_6/tower_1_conv_conv2d_bn"
  top: "mixed_6/tower_1_conv_conv2d_relu"
}
layer {
  name: "mixed_6/tower_1_conv_1_conv2d"
  type: "Convolution"
  bottom: "mixed_6/tower_1_conv_conv2d_relu"
  top: "mixed_6/tower_1_conv_1_conv2d"
  convolution_param {
    bias_term: false
    num_output: 160
    pad_h: 3
pad_w: 0
    kernel_h: 7
kernel_w: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_6/tower_1_conv_1_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_6/tower_1_conv_1_conv2d"
  top: "mixed_6/tower_1_conv_1_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_6/tower_1_conv_1_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_6/tower_1_conv_1_conv2d_bn"
  top: "mixed_6/tower_1_conv_1_conv2d_relu"
}
layer {
  name: "mixed_6/tower_1_conv_2_conv2d"
  type: "Convolution"
  bottom: "mixed_6/tower_1_conv_1_conv2d_relu"
  top: "mixed_6/tower_1_conv_2_conv2d"
  convolution_param {
    bias_term: false
    num_output: 160
    pad_h: 0
pad_w: 3
    kernel_h: 1
kernel_w: 7
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_6/tower_1_conv_2_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_6/tower_1_conv_2_conv2d"
  top: "mixed_6/tower_1_conv_2_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_6/tower_1_conv_2_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_6/tower_1_conv_2_conv2d_bn"
  top: "mixed_6/tower_1_conv_2_conv2d_relu"
}
layer {
  name: "mixed_6/tower_1_conv_3_conv2d"
  type: "Convolution"
  bottom: "mixed_6/tower_1_conv_2_conv2d_relu"
  top: "mixed_6/tower_1_conv_3_conv2d"
  convolution_param {
    bias_term: false
    num_output: 160
    pad_h: 3
pad_w: 0
    kernel_h: 7
kernel_w: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_6/tower_1_conv_3_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_6/tower_1_conv_3_conv2d"
  top: "mixed_6/tower_1_conv_3_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_6/tower_1_conv_3_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_6/tower_1_conv_3_conv2d_bn"
  top: "mixed_6/tower_1_conv_3_conv2d_relu"
}
layer {
  name: "mixed_6/tower_1_conv_4_conv2d"
  type: "Convolution"
  bottom: "mixed_6/tower_1_conv_3_conv2d_relu"
  top: "mixed_6/tower_1_conv_4_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad_h: 0
pad_w: 3
    kernel_h: 1
kernel_w: 7
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_6/tower_1_conv_4_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_6/tower_1_conv_4_conv2d"
  top: "mixed_6/tower_1_conv_4_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_6/tower_1_conv_4_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_6/tower_1_conv_4_conv2d_bn"
  top: "mixed_6/tower_1_conv_4_conv2d_relu"
}
layer {
  name: "mixed_6/tower_2_AVG_pool"
  type: "Pooling"
  bottom: "mixed_5/chconcat"
  top: "mixed_6/tower_2_AVG_pool"
  pooling_param {
    pool: AVE
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "mixed_6/tower_2_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_6/tower_2_AVG_pool"
  top: "mixed_6/tower_2_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_6/tower_2_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_6/tower_2_conv_conv2d"
  top: "mixed_6/tower_2_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_6/tower_2_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_6/tower_2_conv_conv2d_bn"
  top: "mixed_6/tower_2_conv_conv2d_relu"
}
layer {
  name: "mixed_6/chconcat"
  bottom: "mixed_6/conv_conv2d_relu"
bottom: "mixed_6/tower_conv_2_conv2d_relu"
bottom: "mixed_6/tower_1_conv_4_conv2d_relu"
bottom: "mixed_6/tower_2_conv_conv2d_relu"

  top: "mixed_6/chconcat"
  type: "Concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mixed_7/conv_conv2d"
  type: "Convolution"
  bottom: "mixed_6/chconcat"
  top: "mixed_7/conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_7/conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_7/conv_conv2d"
  top: "mixed_7/conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_7/conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_7/conv_conv2d_bn"
  top: "mixed_7/conv_conv2d_relu"
}
layer {
  name: "mixed_7/tower_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_6/chconcat"
  top: "mixed_7/tower_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_7/tower_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_7/tower_conv_conv2d"
  top: "mixed_7/tower_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_7/tower_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_7/tower_conv_conv2d_bn"
  top: "mixed_7/tower_conv_conv2d_relu"
}
layer {
  name: "mixed_7/tower_conv_1_conv2d"
  type: "Convolution"
  bottom: "mixed_7/tower_conv_conv2d_relu"
  top: "mixed_7/tower_conv_1_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad_h: 0
pad_w: 3
    kernel_h: 1
kernel_w: 7
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_7/tower_conv_1_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_7/tower_conv_1_conv2d"
  top: "mixed_7/tower_conv_1_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_7/tower_conv_1_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_7/tower_conv_1_conv2d_bn"
  top: "mixed_7/tower_conv_1_conv2d_relu"
}
layer {
  name: "mixed_7/tower_conv_2_conv2d"
  type: "Convolution"
  bottom: "mixed_7/tower_conv_1_conv2d_relu"
  top: "mixed_7/tower_conv_2_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad_h: 3
pad_w: 0
    kernel_h: 7
kernel_w: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_7/tower_conv_2_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_7/tower_conv_2_conv2d"
  top: "mixed_7/tower_conv_2_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_7/tower_conv_2_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_7/tower_conv_2_conv2d_bn"
  top: "mixed_7/tower_conv_2_conv2d_relu"
}
layer {
  name: "mixed_7/tower_1_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_6/chconcat"
  top: "mixed_7/tower_1_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_7/tower_1_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_7/tower_1_conv_conv2d"
  top: "mixed_7/tower_1_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_7/tower_1_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_7/tower_1_conv_conv2d_bn"
  top: "mixed_7/tower_1_conv_conv2d_relu"
}
layer {
  name: "mixed_7/tower_1_conv_1_conv2d"
  type: "Convolution"
  bottom: "mixed_7/tower_1_conv_conv2d_relu"
  top: "mixed_7/tower_1_conv_1_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad_h: 3
pad_w: 0
    kernel_h: 7
kernel_w: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_7/tower_1_conv_1_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_7/tower_1_conv_1_conv2d"
  top: "mixed_7/tower_1_conv_1_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_7/tower_1_conv_1_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_7/tower_1_conv_1_conv2d_bn"
  top: "mixed_7/tower_1_conv_1_conv2d_relu"
}
layer {
  name: "mixed_7/tower_1_conv_2_conv2d"
  type: "Convolution"
  bottom: "mixed_7/tower_1_conv_1_conv2d_relu"
  top: "mixed_7/tower_1_conv_2_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad_h: 0
pad_w: 3
    kernel_h: 1
kernel_w: 7
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_7/tower_1_conv_2_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_7/tower_1_conv_2_conv2d"
  top: "mixed_7/tower_1_conv_2_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_7/tower_1_conv_2_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_7/tower_1_conv_2_conv2d_bn"
  top: "mixed_7/tower_1_conv_2_conv2d_relu"
}
layer {
  name: "mixed_7/tower_1_conv_3_conv2d"
  type: "Convolution"
  bottom: "mixed_7/tower_1_conv_2_conv2d_relu"
  top: "mixed_7/tower_1_conv_3_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad_h: 3
pad_w: 0
    kernel_h: 7
kernel_w: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_7/tower_1_conv_3_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_7/tower_1_conv_3_conv2d"
  top: "mixed_7/tower_1_conv_3_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_7/tower_1_conv_3_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_7/tower_1_conv_3_conv2d_bn"
  top: "mixed_7/tower_1_conv_3_conv2d_relu"
}
layer {
  name: "mixed_7/tower_1_conv_4_conv2d"
  type: "Convolution"
  bottom: "mixed_7/tower_1_conv_3_conv2d_relu"
  top: "mixed_7/tower_1_conv_4_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad_h: 0
pad_w: 3
    kernel_h: 1
kernel_w: 7
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_7/tower_1_conv_4_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_7/tower_1_conv_4_conv2d"
  top: "mixed_7/tower_1_conv_4_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_7/tower_1_conv_4_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_7/tower_1_conv_4_conv2d_bn"
  top: "mixed_7/tower_1_conv_4_conv2d_relu"
}
layer {
  name: "mixed_7/tower_2_AVG_pool"
  type: "Pooling"
  bottom: "mixed_6/chconcat"
  top: "mixed_7/tower_2_AVG_pool"
  pooling_param {
    pool: AVE
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "mixed_7/tower_2_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_7/tower_2_AVG_pool"
  top: "mixed_7/tower_2_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_7/tower_2_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_7/tower_2_conv_conv2d"
  top: "mixed_7/tower_2_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_7/tower_2_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_7/tower_2_conv_conv2d_bn"
  top: "mixed_7/tower_2_conv_conv2d_relu"
}
layer {
  name: "mixed_7/chconcat"
  bottom: "mixed_7/conv_conv2d_relu"
bottom: "mixed_7/tower_conv_2_conv2d_relu"
bottom: "mixed_7/tower_1_conv_4_conv2d_relu"
bottom: "mixed_7/tower_2_conv_conv2d_relu"

  top: "mixed_7/chconcat"
  type: "Concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mixed_8/tower_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_7/chconcat"
  top: "mixed_8/tower_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_8/tower_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_8/tower_conv_conv2d"
  top: "mixed_8/tower_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_8/tower_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_8/tower_conv_conv2d_bn"
  top: "mixed_8/tower_conv_conv2d_relu"
}
layer {
  name: "mixed_8/tower_conv_1_conv2d"
  type: "Convolution"
  bottom: "mixed_8/tower_conv_conv2d_relu"
  top: "mixed_8/tower_conv_1_conv2d"
  convolution_param {
    bias_term: false
    num_output: 320
    pad: 0
    kernel_size: 3
    stride: 2
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_8/tower_conv_1_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_8/tower_conv_1_conv2d"
  top: "mixed_8/tower_conv_1_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_8/tower_conv_1_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_8/tower_conv_1_conv2d_bn"
  top: "mixed_8/tower_conv_1_conv2d_relu"
}
layer {
  name: "mixed_8/tower_1_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_7/chconcat"
  top: "mixed_8/tower_1_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_8/tower_1_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_8/tower_1_conv_conv2d"
  top: "mixed_8/tower_1_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_8/tower_1_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_8/tower_1_conv_conv2d_bn"
  top: "mixed_8/tower_1_conv_conv2d_relu"
}
layer {
  name: "mixed_8/tower_1_conv_1_conv2d"
  type: "Convolution"
  bottom: "mixed_8/tower_1_conv_conv2d_relu"
  top: "mixed_8/tower_1_conv_1_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad_h: 0
pad_w: 3
    kernel_h: 1
kernel_w: 7
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_8/tower_1_conv_1_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_8/tower_1_conv_1_conv2d"
  top: "mixed_8/tower_1_conv_1_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_8/tower_1_conv_1_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_8/tower_1_conv_1_conv2d_bn"
  top: "mixed_8/tower_1_conv_1_conv2d_relu"
}
layer {
  name: "mixed_8/tower_1_conv_2_conv2d"
  type: "Convolution"
  bottom: "mixed_8/tower_1_conv_1_conv2d_relu"
  top: "mixed_8/tower_1_conv_2_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad_h: 3
pad_w: 0
    kernel_h: 7
kernel_w: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_8/tower_1_conv_2_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_8/tower_1_conv_2_conv2d"
  top: "mixed_8/tower_1_conv_2_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_8/tower_1_conv_2_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_8/tower_1_conv_2_conv2d_bn"
  top: "mixed_8/tower_1_conv_2_conv2d_relu"
}
layer {
  name: "mixed_8/tower_1_conv_3_conv2d"
  type: "Convolution"
  bottom: "mixed_8/tower_1_conv_2_conv2d_relu"
  top: "mixed_8/tower_1_conv_3_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad: 0
    kernel_size: 3
    stride: 2
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_8/tower_1_conv_3_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_8/tower_1_conv_3_conv2d"
  top: "mixed_8/tower_1_conv_3_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_8/tower_1_conv_3_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_8/tower_1_conv_3_conv2d_bn"
  top: "mixed_8/tower_1_conv_3_conv2d_relu"
}
layer {
  name: "mixed_8/max_pool"
  type: "Pooling"
  bottom: "mixed_7/chconcat"
  top: "mixed_8/max_pool"
  pooling_param {
    pool: MAX
    pad: 0
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "mixed_8/chconcat"
  bottom: "mixed_8/tower_conv_1_conv2d_relu"
bottom: "mixed_8/tower_1_conv_3_conv2d_relu"
bottom: "mixed_8/max_pool"

  top: "mixed_8/chconcat"
  type: "Concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mixed_9/conv_conv2d"
  type: "Convolution"
  bottom: "mixed_8/chconcat"
  top: "mixed_9/conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 320
    pad: 0
    kernel_h: 1
kernel_w: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_9/conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_9/conv_conv2d"
  top: "mixed_9/conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_9/conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_9/conv_conv2d_bn"
  top: "mixed_9/conv_conv2d_relu"
}
layer {
  name: "mixed_9/tower_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_8/chconcat"
  top: "mixed_9/tower_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 384
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_9/tower_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_9/tower_conv_conv2d"
  top: "mixed_9/tower_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_9/tower_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_9/tower_conv_conv2d_bn"
  top: "mixed_9/tower_conv_conv2d_relu"
}
layer {
  name: "mixed_9/tower_mixed_conv/conv2d"
  type: "Convolution"
  bottom: "mixed_9/tower_conv_conv2d_relu"
  top: "mixed_9/tower_mixed_conv/conv2d"
  convolution_param {
    bias_term: false
    num_output: 384
    pad_h: 0
pad_w: 1
    kernel_h: 1
kernel_w: 3
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_9/tower_mixed_conv/conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_9/tower_mixed_conv/conv2d"
  top: "mixed_9/tower_mixed_conv/conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_9/tower_mixed_conv/conv2d_relu"
  type: "ReLU"
  bottom: "mixed_9/tower_mixed_conv/conv2d_bn"
  top: "mixed_9/tower_mixed_conv/conv2d_relu"
}
layer {
  name: "mixed_9/tower_mixed_conv/1_conv2d"
  type: "Convolution"
  bottom: "mixed_9/tower_conv_conv2d_relu"
  top: "mixed_9/tower_mixed_conv/1_conv2d"
  convolution_param {
    bias_term: false
    num_output: 384
    pad_h: 1
pad_w: 0
    kernel_h: 3
kernel_w: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_9/tower_mixed_conv/1_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_9/tower_mixed_conv/1_conv2d"
  top: "mixed_9/tower_mixed_conv/1_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_9/tower_mixed_conv/1_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_9/tower_mixed_conv/1_conv2d_bn"
  top: "mixed_9/tower_mixed_conv/1_conv2d_relu"
}
layer {
  name: "mixed_9/tower_1_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_8/chconcat"
  top: "mixed_9/tower_1_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 448
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_9/tower_1_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_9/tower_1_conv_conv2d"
  top: "mixed_9/tower_1_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_9/tower_1_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_9/tower_1_conv_conv2d_bn"
  top: "mixed_9/tower_1_conv_conv2d_relu"
}
layer {
  name: "mixed_9/tower_1_conv_1_conv2d"
  type: "Convolution"
  bottom: "mixed_9/tower_1_conv_conv2d_relu"
  top: "mixed_9/tower_1_conv_1_conv2d"
  convolution_param {
    bias_term: false
    num_output: 384
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_9/tower_1_conv_1_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_9/tower_1_conv_1_conv2d"
  top: "mixed_9/tower_1_conv_1_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_9/tower_1_conv_1_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_9/tower_1_conv_1_conv2d_bn"
  top: "mixed_9/tower_1_conv_1_conv2d_relu"
}
layer {
  name: "mixed_9/tower_1_mixed_conv/conv2d"
  type: "Convolution"
  bottom: "mixed_9/tower_1_conv_1_conv2d_relu"
  top: "mixed_9/tower_1_mixed_conv/conv2d"
  convolution_param {
    bias_term: false
    num_output: 384
    pad_h: 0
pad_w: 1
    kernel_h: 1
kernel_w: 3
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_9/tower_1_mixed_conv/conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_9/tower_1_mixed_conv/conv2d"
  top: "mixed_9/tower_1_mixed_conv/conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_9/tower_1_mixed_conv/conv2d_relu"
  type: "ReLU"
  bottom: "mixed_9/tower_1_mixed_conv/conv2d_bn"
  top: "mixed_9/tower_1_mixed_conv/conv2d_relu"
}
layer {
  name: "mixed_9/tower_1_mixed_conv/1_conv2d"
  type: "Convolution"
  bottom: "mixed_9/tower_1_conv_1_conv2d_relu"
  top: "mixed_9/tower_1_mixed_conv/1_conv2d"
  convolution_param {
    bias_term: false
    num_output: 384
    pad_h: 1
pad_w: 0
    kernel_h: 3
kernel_w: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_9/tower_1_mixed_conv/1_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_9/tower_1_mixed_conv/1_conv2d"
  top: "mixed_9/tower_1_mixed_conv/1_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_9/tower_1_mixed_conv/1_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_9/tower_1_mixed_conv/1_conv2d_bn"
  top: "mixed_9/tower_1_mixed_conv/1_conv2d_relu"
}
layer {
  name: "mixed_9/tower_2_AVG_pool"
  type: "Pooling"
  bottom: "mixed_8/chconcat"
  top: "mixed_9/tower_2_AVG_pool"
  pooling_param {
    pool: AVE
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "mixed_9/tower_2_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_9/tower_2_AVG_pool"
  top: "mixed_9/tower_2_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_9/tower_2_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_9/tower_2_conv_conv2d"
  top: "mixed_9/tower_2_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_9/tower_2_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_9/tower_2_conv_conv2d_bn"
  top: "mixed_9/tower_2_conv_conv2d_relu"
}
layer {
  name: "mixed_9/chconcat"
  bottom: "mixed_9/conv_conv2d_relu"
bottom: "mixed_9/tower_mixed_conv/conv2d_relu"
bottom: "mixed_9/tower_mixed_conv/1_conv2d_relu"
bottom: "mixed_9/tower_1_mixed_conv/conv2d_relu"
bottom: "mixed_9/tower_1_mixed_conv/1_conv2d_relu"
bottom: "mixed_9/tower_2_conv_conv2d_relu"

  top: "mixed_9/chconcat"
  type: "Concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mixed_10/conv_conv2d"
  type: "Convolution"
  bottom: "mixed_9/chconcat"
  top: "mixed_10/conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 320
    pad: 0
    kernel_h: 1
kernel_w: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_10/conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_10/conv_conv2d"
  top: "mixed_10/conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_10/conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_10/conv_conv2d_bn"
  top: "mixed_10/conv_conv2d_relu"
}
layer {
  name: "mixed_10/tower_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_9/chconcat"
  top: "mixed_10/tower_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 384
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_10/tower_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_10/tower_conv_conv2d"
  top: "mixed_10/tower_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_10/tower_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_10/tower_conv_conv2d_bn"
  top: "mixed_10/tower_conv_conv2d_relu"
}
layer {
  name: "mixed_10/tower_mixed_conv/conv2d"
  type: "Convolution"
  bottom: "mixed_10/tower_conv_conv2d_relu"
  top: "mixed_10/tower_mixed_conv/conv2d"
  convolution_param {
    bias_term: false
    num_output: 384
    pad_h: 0
pad_w: 1
    kernel_h: 1
kernel_w: 3
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_10/tower_mixed_conv/conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_10/tower_mixed_conv/conv2d"
  top: "mixed_10/tower_mixed_conv/conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_10/tower_mixed_conv/conv2d_relu"
  type: "ReLU"
  bottom: "mixed_10/tower_mixed_conv/conv2d_bn"
  top: "mixed_10/tower_mixed_conv/conv2d_relu"
}
layer {
  name: "mixed_10/tower_mixed_conv/1_conv2d"
  type: "Convolution"
  bottom: "mixed_10/tower_conv_conv2d_relu"
  top: "mixed_10/tower_mixed_conv/1_conv2d"
  convolution_param {
    bias_term: false
    num_output: 384
    pad_h: 1
pad_w: 0
    kernel_h: 3
kernel_w: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_10/tower_mixed_conv/1_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_10/tower_mixed_conv/1_conv2d"
  top: "mixed_10/tower_mixed_conv/1_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_10/tower_mixed_conv/1_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_10/tower_mixed_conv/1_conv2d_bn"
  top: "mixed_10/tower_mixed_conv/1_conv2d_relu"
}
layer {
  name: "mixed_10/tower_1_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_9/chconcat"
  top: "mixed_10/tower_1_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 448
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_10/tower_1_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_10/tower_1_conv_conv2d"
  top: "mixed_10/tower_1_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_10/tower_1_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_10/tower_1_conv_conv2d_bn"
  top: "mixed_10/tower_1_conv_conv2d_relu"
}
layer {
  name: "mixed_10/tower_1_conv_1_conv2d"
  type: "Convolution"
  bottom: "mixed_10/tower_1_conv_conv2d_relu"
  top: "mixed_10/tower_1_conv_1_conv2d"
  convolution_param {
    bias_term: false
    num_output: 384
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_10/tower_1_conv_1_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_10/tower_1_conv_1_conv2d"
  top: "mixed_10/tower_1_conv_1_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_10/tower_1_conv_1_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_10/tower_1_conv_1_conv2d_bn"
  top: "mixed_10/tower_1_conv_1_conv2d_relu"
}
layer {
  name: "mixed_10/tower_1_mixed_conv/conv2d"
  type: "Convolution"
  bottom: "mixed_10/tower_1_conv_1_conv2d_relu"
  top: "mixed_10/tower_1_mixed_conv/conv2d"
  convolution_param {
    bias_term: false
    num_output: 384
    pad_h: 0
pad_w: 1
    kernel_h: 1
kernel_w: 3
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_10/tower_1_mixed_conv/conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_10/tower_1_mixed_conv/conv2d"
  top: "mixed_10/tower_1_mixed_conv/conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_10/tower_1_mixed_conv/conv2d_relu"
  type: "ReLU"
  bottom: "mixed_10/tower_1_mixed_conv/conv2d_bn"
  top: "mixed_10/tower_1_mixed_conv/conv2d_relu"
}
layer {
  name: "mixed_10/tower_1_mixed_conv/1_conv2d"
  type: "Convolution"
  bottom: "mixed_10/tower_1_conv_1_conv2d_relu"
  top: "mixed_10/tower_1_mixed_conv/1_conv2d"
  convolution_param {
    bias_term: false
    num_output: 384
    pad_h: 1
pad_w: 0
    kernel_h: 3
kernel_w: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_10/tower_1_mixed_conv/1_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_10/tower_1_mixed_conv/1_conv2d"
  top: "mixed_10/tower_1_mixed_conv/1_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_10/tower_1_mixed_conv/1_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_10/tower_1_mixed_conv/1_conv2d_bn"
  top: "mixed_10/tower_1_mixed_conv/1_conv2d_relu"
}
layer {
  name: "mixed_10/max_pool"
  type: "Pooling"
  bottom: "mixed_9/chconcat"
  top: "mixed_10/max_pool"
  pooling_param {
    pool: MAX
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "mixed_10/tower_2_conv_conv2d"
  type: "Convolution"
  bottom: "mixed_10/max_pool"
  top: "mixed_10/tower_2_conv_conv2d"
  convolution_param {
    bias_term: false
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
        type: "xavier"
    }
  }

}
layer {
  name: "mixed_10/tower_2_conv_conv2d_bn"
  type: "BatchNorm"
  bottom: "mixed_10/tower_2_conv_conv2d"
  top: "mixed_10/tower_2_conv_conv2d_bn"
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "mixed_10/tower_2_conv_conv2d_relu"
  type: "ReLU"
  bottom: "mixed_10/tower_2_conv_conv2d_bn"
  top: "mixed_10/tower_2_conv_conv2d_relu"
}
layer {
  name: "mixed_10/chconcat"
  bottom: "mixed_10/conv_conv2d_relu"
bottom: "mixed_10/tower_mixed_conv/conv2d_relu"
bottom: "mixed_10/tower_mixed_conv/1_conv2d_relu"
bottom: "mixed_10/tower_1_mixed_conv/conv2d_relu"
bottom: "mixed_10/tower_1_mixed_conv/1_conv2d_relu"
bottom: "mixed_10/tower_2_conv_conv2d_relu"

  top: "mixed_10/chconcat"
  type: "Concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "mixed_10/chconcat"
  top: "global_pool"
  pooling_param {
    pool: AVE
    pad: 0
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "flatten"
  type: "Flatten"
  bottom: "global_pool"
  top: "flatten"
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "flatten"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
     num_output: 1000
     weight_filler {
       type: "xavier"
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc1"
  top: "loss"
}
layer {
  name: "acc/top-1"
  type: "Accuracy"
  bottom: "fc1"
  top: "acc/top-1"
  include {
    phase: TEST
  }
}
layer {
  name: "acc/top-5"
  type: "Accuracy"
  bottom: "fc1"
  top: "acc/top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}